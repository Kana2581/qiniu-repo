"""
voice_util.py - ä¸ƒç‰›äº‘è¯­éŸ³å·¥å…·é›†ï¼ˆTTS + ASRï¼‰
----------------------------------------------
åŠŸèƒ½ï¼š
- æ–‡æœ¬è½¬è¯­éŸ³ (Text-to-Speech)
- è¯­éŸ³è½¬æ–‡æœ¬ (Automatic Speech Recognition)

ç¤ºä¾‹ï¼š
    from voice_util import TTSClient, ASRClient

    tts = TTSClient(api_key="your_api_key_here")
    tts.text_to_speech("ä½ å¥½ï¼Œä¸–ç•Œ", "hello.mp3")

    asr = ASRClient(api_key="your_api_key_here")
    result = asr.speech_to_text("https://example.com/audio.mp3")
    print(result)
"""
import io
import re

import requests
import base64


# =====================
# TTS å®¢æˆ·ç«¯
# =====================
import requests
import base64
from pydub import AudioSegment
class TTSClient:
    def __init__(self, api_key: str, base_url: str = "https://openai.qiniu.com/v1/voice/tts"):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"{self.api_key}"
        }

    def text_to_speech(
        self,
        text: str,
        voice_type: str = "qiniu_zh_female_wwxkjx",
        encoding: str = "wav",
        speed_ratio: float = 1.0,
    ) -> str | None:
        """
        è¿”å›ç”Ÿæˆçš„è¯­éŸ³äºŒè¿›åˆ¶æ•°æ®
        """
        payload = {
            "audio": {
                "voice_type": voice_type,
                "encoding": encoding,
                "speed_ratio": speed_ratio
            },
            "request": {
                "text": text
            }
        }

        try:
            response = requests.post(self.base_url, headers=self.headers, json=payload)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"è¯·æ±‚å‡ºé”™: {e}")
            return None

        data = response.json()
        audio_base64 = data.get("audio") or data.get("data")
        return audio_base64


    def base64_to_bytes(self,audio_base64)-> bytes|None:
        if not audio_base64:
            return None

        try:
            audio_bytes = base64.b64decode(audio_base64)
            return audio_bytes
        except Exception as e:
            print(f"è§£ç éŸ³é¢‘æ•°æ®å¤±è´¥ï¼š{e}")
            return None



# =====================
# ASR å®¢æˆ·ç«¯
# =====================
class ASRClient:
    def __init__(self, api_key: str, base_url: str = "https://openai.qiniu.com/v1/voice/asr"):
        self.api_key = api_key
        self.base_url = base_url
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

    def speech_to_text(self, audio_url: str, audio_format: str = "mp3"):
        """
        è°ƒç”¨ ASR æ¥å£è¿›è¡Œè¯­éŸ³è¯†åˆ«
        :param audio_url: éŸ³é¢‘æ–‡ä»¶çš„å…¬ç½‘ URL
        :param audio_format: éŸ³é¢‘æ ¼å¼ï¼ˆé»˜è®¤ mp3ï¼‰
        :return: è¯†åˆ«å‡ºçš„æ–‡æœ¬æˆ– None
        """
        payload = {
            "model": "asr",
            "audio": {
                "format": audio_format,
                "url": audio_url
            }
        }

        try:
            response = requests.post(self.base_url, headers=self.headers, json=payload)
            response.raise_for_status()
        except requests.RequestException as e:
            print(f"è¯·æ±‚å‡ºé”™: {e}")
            return None

        data = response.json()
        try:
            text = data["data"]["result"]["text"]
            print(f"âœ… è¯†åˆ«ç»“æœ: {text}")
            return text
        except KeyError:
            print("âš ï¸ æœªæ‰¾åˆ°è¯†åˆ«æ–‡æœ¬ï¼Œè¯·æ£€æŸ¥å“åº”ç»“æ„ï¼š")
            print(data)
            return None


def has_punctuation(text):
    """åˆ¤æ–­æ˜¯å¦åŒ…å«å¸¸è§æ ‡ç‚¹"""
    return re.search(r"[ã€‚ï¼Ÿï¼ï¼›ï¼Œ,.!?ã€]", text) is not None

def is_sentence_end(text):
    """åˆ¤æ–­æ˜¯å¦ä¸ºå®Œæ•´å¥å­çš„ç»“å°¾"""
    return re.search(r"[ã€‚ï¼Ÿï¼!?\n]$", text.strip()) is not None

def text_to_speech_segments(stream_tokens, call_tts_api, min_len=10, max_len=40):
    """
    ä»å¤§æ¨¡å‹æµä¸­æ”¶é›†æ–‡æœ¬ï¼š
    - å½“é•¿åº¦>min_len ä¸”æœ«å°¾æ˜¯å¥æœ«æ ‡ç‚¹æ—¶è§¦å‘ï¼›
    - è‹¥è¶…è¿‡max_lenåˆ™å¼ºåˆ¶è§¦å‘ï¼›
    - é¿å…å¥å­è¢«é€—å·åˆ‡æ–­ï¼›
    """
    buffer = ""
    audio_segments = []

    for token in stream_tokens:
        buffer += token
        buffer.replace("**", "")
        # åˆ¤æ–­æ˜¯å¦å¯ä»¥è§¦å‘
        if len(buffer) >= min_len and has_punctuation(buffer):
            if is_sentence_end(buffer) or len(buffer) >= max_len:
                # âœ… å¥æœ«æ ‡ç‚¹æˆ–å¤ªé•¿ -> è§¦å‘TTS
                text_piece = buffer.strip()
                audio_b64 = call_tts_api(text_piece)
                audio_segments.append(audio_b64)
                buffer = ""  # æ¸…ç©ºç¼“å†²
            else:
                # âš ï¸ åªæ˜¯é€—å·ç±»æ ‡ç‚¹ï¼Œç»§ç»­ç­‰å¾…æ›´å¤šå†…å®¹
                continue

    # ğŸ”š æ”¶å°¾ï¼šå¦‚æœè¿˜æœ‰æœªå¤„ç†çš„å†…å®¹ï¼Œç•™ç»™ä¸‹ä¸€æ¬¡æ‹¼æ¥
    if buffer.strip():
        return audio_segments, buffer.strip()  # ğŸ‘ˆ æŠŠå‰©ä½™éƒ¨åˆ†è¿”å›ä»¥ä¾¿åç»­æ‹¼æ¥
    else:
        return audio_segments, ""


# ========== ä¸‰ã€æ‹¼æ¥éŸ³é¢‘å‡½æ•° ==========
def merge_audio_base64_segments(audio_base64_list):
    """
    å°†å¤šä¸ª base64 éŸ³é¢‘ç‰‡æ®µæ‹¼æ¥æˆä¸€ä¸ªå®Œæ•´éŸ³é¢‘ï¼ˆè¿”å›bytesï¼‰
    """
    combined = AudioSegment.silent(duration=0)  # å¼€å§‹ç©ºéŸ³é¢‘
    for idx, audio_b64 in enumerate(audio_base64_list):
        if audio_b64:
            audio_data = base64.b64decode(audio_b64)
            segment = AudioSegment.from_file(io.BytesIO(audio_data),  format="wav")
            combined += segment


    # å¯¼å‡ºæ‹¼æ¥åçš„å®Œæ•´éŸ³é¢‘
    output_buffer = io.BytesIO()
    combined.export(output_buffer, format="wav")
    return output_buffer.getvalue()